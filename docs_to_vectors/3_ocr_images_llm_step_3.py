#!/usr/bin/env python3
import asyncio
import aiohttp
import json
from pathlib import Path
from aiofiles import open as aio_open
from aiofiles.os import path as aio_path
from tqdm import tqdm

number = "54"

# === –ù–ê–°–¢–†–û–ô–ö–ò ===
INPUT_DIR = Path(f"docs/{number}/jpeg")
TMP_DIR = Path(f"docs/{number}/tmp")
FINAL_OUTPUT = Path(f"docs/{number}/{number}.txt")
ENDPOINT = "http://192.168.168.10:8000/ocr_main_text"
CONCURRENCY = 8  # –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–æ—Ç–æ–∫–æ–≤

# === –°–æ–∑–¥–∞–Ω–∏–µ tmp-–ø–∞–ø–∫–∏ ===
TMP_DIR.mkdir(exist_ok=True)

async def process_batch(name, session, batch):
    bar = tqdm(batch, desc=f"–ü–æ—Ç–æ–∫ {name}", position=name, leave=False)
    for img_path in bar:
        tmp_path = TMP_DIR / (img_path.stem + ".json")
        if await aio_path.exists(tmp_path):
            bar.set_postfix_str(f"‚úÖ –ü—Ä–æ–ø—É—â–µ–Ω–æ: {img_path.name}")
            continue

        try:
            with img_path.open("rb") as f:
                img_data = f.read()

            data = aiohttp.FormData()
            data.add_field("file", img_data, filename=img_path.name, content_type="image/jpeg")

            async with session.post(ENDPOINT, data=data, timeout=aiohttp.ClientTimeout(total=900)) as resp:
                resp.raise_for_status()
                result = await resp.json()
                text = result.get("text", "").strip()

                async with aio_open(tmp_path, "w", encoding="utf-8") as f:
                    await f.write(json.dumps({
                        "filename": img_path.name,
                        "text": text
                    }, ensure_ascii=False, indent=2))

                bar.set_postfix_str(f"‚úÖ –ì–æ—Ç–æ–≤–æ: {img_path.name}")
        except Exception as e:
            bar.set_postfix_str(f"‚ùå –û—à–∏–±–∫–∞: {img_path.name} ‚Üí {e}")

async def main():
    images = sorted(INPUT_DIR.glob("*.jpg"))
    total = len(images)
    print(f"üîç –ù–∞–π–¥–µ–Ω–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π: {total}")

    # –†–∞–∑–±–∏–≤–∞–µ–º –Ω–∞ N —á–∞—Å—Ç–µ–π
    chunks = [images[i::CONCURRENCY] for i in range(CONCURRENCY)]

    async with aiohttp.ClientSession() as session:
        tasks = [
            process_batch(i, session, chunk)
            for i, chunk in enumerate(chunks)
        ]
        await asyncio.gather(*tasks)

    # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–æ
    tmp_files = sorted(TMP_DIR.glob("*.json"))
    processed = len(tmp_files)

    if processed < total:
        print(f"‚è∏ –í—Å–µ–≥–æ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–æ: {processed} –∏–∑ {total}.")
        missing = [img.name for img in images if not (TMP_DIR / (img.stem + ".json")).exists()]
        if missing:
            print("‚ùó –ù–µ –æ–±—Ä–∞–±–æ—Ç–∞–Ω—ã —Å–ª–µ–¥—É—é—â–∏–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è:")
            for name in missing:
                print(f" - {name}")
        return

    print(f"‚úÖ –í—Å–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –æ–±—Ä–∞–±–æ—Ç–∞–Ω—ã: {processed} –∏–∑ {total}.")
    print("üì¶ –°–æ–±–∏—Ä–∞–µ–º —Ñ–∏–Ω–∞–ª—å–Ω—ã–π —Ñ–∞–π–ª‚Ä¶")

    async with aio_open(FINAL_OUTPUT, "w", encoding="utf-8") as out:
        for tmp in tmp_files:
            async with aio_open(tmp, "r", encoding="utf-8") as f:
                data = json.loads(await f.read())
                text = data.get("text", "").strip()

                # üîç –û—á–∏—â–∞–µ–º –æ—Ç –≤—Å—Ç–∞–≤–æ–∫, markdown –∏ –ø—Ä–µ—Ñ–∏–∫—Å–æ–≤
                lines = text.splitlines()
                junk_prefixes = [
                    "here is", "respuesta:", "transcripci√≥n", "```", "respuesta extra√≠da",
                    "extracted main body text", "respuesta ocr", "json", "output:"
                ]
                while lines and any(p in lines[0].lower() for p in junk_prefixes):
                    lines.pop(0)

                clean_text = "\n".join(lines).strip()
                await out.write(clean_text + "\n\n")

    print(f"‚úÖ –§–∏–Ω–∞–ª—å–Ω—ã–π —Ñ–∞–π–ª —Å–æ—Ö—Ä–∞–Ω—ë–Ω –≤ {FINAL_OUTPUT}")

if __name__ == "__main__":
    asyncio.run(main())
